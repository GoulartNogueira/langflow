{"chains":{"ConversationChain":{"template":{"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"memory","type":"BaseMemory","list":false},"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"verbose","type":"bool","list":false},"prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"value":{"input_variables":["history","input"],"output_parser":null,"partial_variables":{},"template":"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n{history}\nHuman: {input}\nAI:","template_format":"f-string","validate_template":true,"_type":"prompt"},"password":false,"name":"prompt","type":"BasePromptTemplate","list":false},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLanguageModel","list":false},"output_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"response","password":false,"name":"output_key","type":"str","list":false},"input_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"input","password":false,"name":"input_key","type":"str","list":false},"_type":"ConversationChain"},"description":"Chain to have a conversation and load context from memory.","base_classes":["LLMChain","ConversationChain","Chain"]},"LLMChain":{"template":{"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"memory","type":"BaseMemory","list":false},"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"verbose","type":"bool","list":false},"prompt":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"prompt","type":"BasePromptTemplate","list":false},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLanguageModel","list":false},"output_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"text","password":false,"name":"output_key","type":"str","list":false},"_type":"LLMChain"},"description":"Chain to run queries against LLMs.","base_classes":["LLMChain","Chain"]},"LLMCheckerChain":{"template":{"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"memory","type":"BaseMemory","list":false},"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"verbose","type":"bool","list":false},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLLM","list":false},"create_draft_answer_prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"value":{"input_variables":["question"],"output_parser":null,"partial_variables":{},"template":"{question}\n\n","template_format":"f-string","validate_template":true,"_type":"prompt"},"password":false,"name":"create_draft_answer_prompt","type":"PromptTemplate","list":false},"list_assertions_prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"value":{"input_variables":["statement"],"output_parser":null,"partial_variables":{},"template":"Here is a statement:\n{statement}\nMake a bullet point list of the assumptions you made when producing the above statement.\n\n","template_format":"f-string","validate_template":true,"_type":"prompt"},"password":false,"name":"list_assertions_prompt","type":"PromptTemplate","list":false},"check_assertions_prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"value":{"input_variables":["assertions"],"output_parser":null,"partial_variables":{},"template":"Here is a bullet point list of assertions:\n{assertions}\nFor each assertion, determine whether it is true or false. If it is false, explain why.\n\n","template_format":"f-string","validate_template":true,"_type":"prompt"},"password":false,"name":"check_assertions_prompt","type":"PromptTemplate","list":false},"revised_answer_prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"value":{"input_variables":["checked_assertions","question"],"output_parser":null,"partial_variables":{},"template":"{checked_assertions}\n\nQuestion: In light of the above assertions and checks, how would you answer the question '{question}'?\n\nAnswer:","template_format":"f-string","validate_template":true,"_type":"prompt"},"password":false,"name":"revised_answer_prompt","type":"PromptTemplate","list":false},"input_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"query","password":false,"name":"input_key","type":"str","list":false},"output_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"result","password":false,"name":"output_key","type":"str","list":false},"_type":"LLMCheckerChain"},"description":"Chain for question-answering with self-verification.","base_classes":["LLMCheckerChain","Chain"]},"LLMMathChain":{"template":{"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"memory","type":"BaseMemory","list":false},"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"verbose","type":"bool","list":false},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLanguageModel","list":false},"prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"value":{"input_variables":["question"],"output_parser":null,"partial_variables":{},"template":"Translate a math problem into Python code that can be executed in Python 3 REPL. Use the output of running this code to answer the question.\n\nQuestion: ${{Question with math problem.}}\n```python\n${{Code that solves the problem and prints the solution}}\n```\n```output\n${{Output of running the code}}\n```\nAnswer: ${{Answer}}\n\nBegin.\n\nQuestion: What is 37593 * 67?\n\n```python\nprint(37593 * 67)\n```\n```output\n2518731\n```\nAnswer: 2518731\n\nQuestion: {question}\n","template_format":"f-string","validate_template":true,"_type":"prompt"},"password":false,"name":"prompt","type":"BasePromptTemplate","list":false},"input_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"question","password":false,"name":"input_key","type":"str","list":false},"output_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"answer","password":false,"name":"output_key","type":"str","list":false},"_type":"LLMMathChain"},"description":"Chain that interprets a prompt and executes python code to do math.","base_classes":["LLMMathChain","Chain"]},"SeriesCharacterChain":{"template":{"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"value":{"chat_memory":{"messages":[]},"output_key":null,"input_key":null,"return_messages":false,"human_prefix":"Human","ai_prefix":"AI","memory_key":"history"},"password":false,"name":"memory","type":"BaseMemory","list":false},"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"verbose","type":"bool","list":false},"prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"value":{"input_variables":["history","input"],"output_parser":null,"partial_variables":{},"template":"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n{history}\nHuman: {input}\nAI:","template_format":"f-string","validate_template":true,"_type":"prompt"},"password":false,"name":"prompt","type":"BasePromptTemplate","list":false},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLanguageModel","list":false},"output_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"response","password":false,"name":"output_key","type":"str","list":false},"input_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"input","password":false,"name":"input_key","type":"str","list":false},"template":{"required":false,"placeholder":"","show":false,"multiline":true,"value":"I want you to act like {character} from {series}.\nI want you to respond and answer like {character}. do not write any explanations. only answer like {character}.\nYou must know all of the knowledge of {character}.\nCurrent conversation:\n{history}\nHuman: {input}\n{character}:","password":false,"name":"template","type":"str","list":false},"ai_prefix_value":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"character","password":false,"name":"ai_prefix_value","type":"str","list":false},"character":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"character","type":"str","list":false},"series":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"series","type":"str","list":false},"_type":"SeriesCharacterChain"},"description":"SeriesCharacterChain is a chain you can use to have a conversation with a character from a series.","base_classes":["Chain","SeriesCharacterChain","LLMChain","ConversationChain","BaseCustomChain"]},"MidJourneyPromptChain":{"template":{"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"value":{"chat_memory":{"messages":[]},"output_key":null,"input_key":null,"return_messages":false,"human_prefix":"Human","ai_prefix":"AI","memory_key":"history"},"password":false,"name":"memory","type":"BaseMemory","list":false},"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"verbose","type":"bool","list":false},"prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"value":{"input_variables":["history","input"],"output_parser":null,"partial_variables":{},"template":"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n{history}\nHuman: {input}\nAI:","template_format":"f-string","validate_template":true,"_type":"prompt"},"password":false,"name":"prompt","type":"BasePromptTemplate","list":false},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLanguageModel","list":false},"output_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"response","password":false,"name":"output_key","type":"str","list":false},"input_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"input","password":false,"name":"input_key","type":"str","list":false},"template":{"required":false,"placeholder":"","show":false,"multiline":true,"value":"I want you to act as a prompt generator for Midjourney's artificial intelligence program.\n    Your job is to provide detailed and creative descriptions that will inspire unique and interesting images from the AI.\n    Keep in mind that the AI is capable of understanding a wide range of language and can interpret abstract concepts, so feel free to be as imaginative and descriptive as possible.\n    For example, you could describe a scene from a futuristic city, or a surreal landscape filled with strange creatures.\n    The more detailed and imaginative your description, the more interesting the resulting image will be. Here is your first prompt:\n    \"A field of wildflowers stretches out as far as the eye can see, each one a different color and shape. In the distance, a massive tree towers over the landscape, its branches reaching up to the sky like tentacles.\"\n\n    Current conversation:\n    {history}\n    Human: {input}\n    AI:","password":false,"name":"template","type":"str","list":false},"ai_prefix_value":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"ai_prefix_value","type":"str","list":false},"_type":"MidJourneyPromptChain"},"description":"MidJourneyPromptChain is a chain you can use to generate new MidJourney prompts.","base_classes":["Chain","MidJourneyPromptChain","LLMChain","ConversationChain","BaseCustomChain"]},"TimeTravelGuideChain":{"template":{"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"value":{"chat_memory":{"messages":[]},"output_key":null,"input_key":null,"return_messages":false,"human_prefix":"Human","ai_prefix":"AI","memory_key":"history"},"password":false,"name":"memory","type":"BaseMemory","list":false},"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"verbose","type":"bool","list":false},"prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"value":{"input_variables":["history","input"],"output_parser":null,"partial_variables":{},"template":"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n{history}\nHuman: {input}\nAI:","template_format":"f-string","validate_template":true,"_type":"prompt"},"password":false,"name":"prompt","type":"BasePromptTemplate","list":false},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLanguageModel","list":false},"output_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"response","password":false,"name":"output_key","type":"str","list":false},"input_key":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"input","password":false,"name":"input_key","type":"str","list":false},"template":{"required":false,"placeholder":"","show":false,"multiline":true,"value":"I want you to act as my time travel guide. You are helpful and creative. I will provide you with the historical period or future time I want to visit and you will suggest the best events, sights, or people to experience. Provide the suggestions and any necessary information.\n    Current conversation:\n    {history}\n    Human: {input}\n    AI:","password":false,"name":"template","type":"str","list":false},"ai_prefix_value":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"ai_prefix_value","type":"str","list":false},"_type":"TimeTravelGuideChain"},"description":"","base_classes":["Chain","LLMChain","TimeTravelGuideChain","ConversationChain","BaseCustomChain"]}},"agents":{"ZeroShotAgent":{"template":{"llm_chain":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm_chain","type":"LLMChain","list":false},"allowed_tools":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"allowed_tools","type":"Tool","list":true},"_type":"ZeroShotAgent"},"description":"Agent for the MRKL chain.","base_classes":["BaseSingleActionAgent","ZeroShotAgent","Agent","function"]},"JsonAgent":{"template":{"toolkit":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"toolkit","type":"BaseToolkit","list":false},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLanguageModel","list":false},"_type":"json_agent"},"description":"Construct a json agent from an LLM and tools.","base_classes":["AgentExecutor"]},"CSVAgent":{"template":{"path":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"","suffixes":[".csv"],"fileTypes":["csv"],"password":false,"name":"path","type":"file","list":false,"content":null},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLanguageModel","list":false},"_type":"csv_agent"},"description":"Construct a json agent from a CSV and tools.","base_classes":["AgentExecutor"]},"initialize_agent":{"template":{"agent":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"zero-shot-react-description","password":false,"options":["zero-shot-react-description","react-docstore","self-ask-with-search","conversational-react-description"],"name":"agent","type":"str","list":true},"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"memory","type":"BaseChatMemory","list":false},"tools":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"tools","type":"Tool","list":true},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLanguageModel","list":false},"_type":"initailize_agent"},"description":"Construct a json agent from an LLM and tools.","base_classes":["AgentExecutor"]}},"prompts":{"PromptTemplate":{"template":{"input_variables":{"required":true,"placeholder":"","show":false,"multiline":false,"password":false,"name":"input_variables","type":"str","list":true},"output_parser":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"output_parser","type":"BaseOutputParser","list":false},"partial_variables":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"partial_variables","type":"code","list":false},"template":{"required":true,"placeholder":"","show":true,"multiline":true,"password":false,"name":"template","type":"prompt","list":false},"template_format":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"f-string","password":false,"name":"template_format","type":"str","list":false},"validate_template":{"required":false,"placeholder":"","show":false,"multiline":false,"value":true,"password":false,"name":"validate_template","type":"bool","list":false},"_type":"PromptTemplate"},"description":"Schema to represent a prompt for an LLM.","base_classes":["StringPromptTemplate","BasePromptTemplate","PromptTemplate"]},"FewShotPromptTemplate":{"template":{"input_variables":{"required":true,"placeholder":"","show":false,"multiline":false,"password":false,"name":"input_variables","type":"str","list":true},"output_parser":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"output_parser","type":"BaseOutputParser","list":false},"partial_variables":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"partial_variables","type":"code","list":false},"examples":{"required":false,"placeholder":"","show":true,"multiline":true,"password":false,"name":"examples","type":"prompt","list":true},"example_selector":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"example_selector","type":"BaseExampleSelector","list":false},"example_prompt":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"example_prompt","type":"PromptTemplate","list":false},"suffix":{"required":true,"placeholder":"","show":true,"multiline":true,"password":false,"name":"suffix","type":"prompt","list":false},"example_separator":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"\n\n","password":false,"name":"example_separator","type":"str","list":false},"prefix":{"required":false,"placeholder":"","show":true,"multiline":true,"value":"","password":false,"name":"prefix","type":"prompt","list":false},"template_format":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"f-string","password":false,"name":"template_format","type":"str","list":false},"validate_template":{"required":false,"placeholder":"","show":false,"multiline":false,"value":true,"password":false,"name":"validate_template","type":"bool","list":false},"_type":"FewShotPromptTemplate"},"description":"Prompt template that contains few shot examples.","base_classes":["FewShotPromptTemplate","StringPromptTemplate","BasePromptTemplate"]},"ZeroShotPrompt":{"template":{"prefix":{"required":false,"placeholder":"","show":true,"multiline":true,"value":"Answer the following questions as best you can. You have access to the following tools:","password":false,"name":"prefix","type":"str","list":false},"suffix":{"required":true,"placeholder":"","show":true,"multiline":true,"value":"Begin!\n\nQuestion: {input}\nThought:{agent_scratchpad}","password":false,"name":"suffix","type":"str","list":false},"format_instructions":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"Use the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question","password":false,"name":"format_instructions","type":"str","list":false},"_type":"zero_shot"},"description":"Prompt template for Zero Shot Agent.","base_classes":["BasePromptTemplate"]}},"llms":{"HuggingFaceHub":{"template":{"cache":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"cache","type":"bool","list":false},"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"verbose","type":"bool","list":false},"client":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"client","type":"Any","list":false},"repo_id":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"gpt2","password":false,"name":"repo_id","type":"str","list":false},"task":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"options":["text-generation","text2text-generation"],"name":"task","type":"str","list":true},"model_kwargs":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"model_kwargs","type":"code","list":false},"huggingfacehub_api_token":{"required":true,"placeholder":"","show":true,"multiline":false,"password":true,"name":"huggingfacehub_api_token","display_name":"HuggingFace Hub API Token","type":"str","list":false},"_type":"HuggingFaceHub"},"description":"Wrapper around HuggingFaceHub  models.To use, you should have the ``huggingface_hub`` python package installed, and theenvironment variable ``HUGGINGFACEHUB_API_TOKEN`` set with your API token, or passit as a named parameter to the constructor.Only supports `text-generation` and `text2text-generation` for now.","base_classes":["HuggingFaceHub","BaseLanguageModel","LLM","BaseLLM"]},"LlamaCpp":{"template":{"cache":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"cache","type":"bool","list":false},"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"verbose","type":"bool","list":false},"client":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"client","type":"Any","list":false},"model_path":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"model_path","type":"str","list":false},"n_ctx":{"required":false,"placeholder":"","show":false,"multiline":false,"value":512,"password":false,"name":"n_ctx","type":"int","list":false},"n_parts":{"required":false,"placeholder":"","show":false,"multiline":false,"value":-1,"password":false,"name":"n_parts","type":"int","list":false},"seed":{"required":false,"placeholder":"","show":false,"multiline":false,"value":-1,"password":false,"name":"seed","type":"int","list":false},"f16_kv":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"f16_kv","type":"bool","list":false},"logits_all":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"logits_all","type":"bool","list":false},"vocab_only":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"vocab_only","type":"bool","list":false},"use_mlock":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"use_mlock","type":"bool","list":false},"n_threads":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"n_threads","type":"int","list":false},"suffix":{"required":false,"placeholder":"","show":false,"multiline":true,"password":false,"name":"suffix","type":"str","list":false},"max_tokens":{"required":false,"placeholder":"","show":true,"multiline":false,"value":256,"password":true,"name":"max_tokens","type":"int","list":false},"temperature":{"required":false,"placeholder":"","show":true,"multiline":false,"value":0.8,"password":false,"name":"temperature","type":"float","list":false},"top_p":{"required":false,"placeholder":"","show":false,"multiline":false,"value":0.95,"password":false,"name":"top_p","type":"float","list":false},"logprobs":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"logprobs","type":"int","list":false},"echo":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"echo","type":"bool","list":false},"stop":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"stop","type":"str","list":true},"repeat_penalty":{"required":false,"placeholder":"","show":false,"multiline":false,"value":1.1,"password":false,"name":"repeat_penalty","type":"float","list":false},"top_k":{"required":false,"placeholder":"","show":false,"multiline":false,"value":40,"password":false,"name":"top_k","type":"int","list":false},"_type":"LlamaCpp"},"description":"Wrapper around the llama.cpp model.To use, you should have the llama-cpp-python library installed, and provide thepath to the Llama model as a named parameter to the constructor.Check out: https://github.com/abetlen/llama-cpp-python","base_classes":["LlamaCpp","BaseLanguageModel","LLM","BaseLLM"]},"OpenAI":{"template":{"cache":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"cache","type":"bool","list":false},"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"verbose","type":"bool","list":false},"client":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"client","type":"Any","list":false},"model_name":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"text-davinci-003","password":false,"options":["text-davinci-003","text-davinci-002","text-curie-001","text-babbage-001","text-ada-001"],"name":"model_name","type":"str","list":true},"temperature":{"required":false,"placeholder":"","show":true,"multiline":false,"value":0.7,"password":false,"name":"temperature","type":"float","list":false},"max_tokens":{"required":false,"placeholder":"","show":true,"multiline":false,"value":256,"password":true,"name":"max_tokens","type":"int","list":false},"top_p":{"required":false,"placeholder":"","show":false,"multiline":false,"value":1,"password":false,"name":"top_p","type":"float","list":false},"frequency_penalty":{"required":false,"placeholder":"","show":false,"multiline":false,"value":0,"password":false,"name":"frequency_penalty","type":"float","list":false},"presence_penalty":{"required":false,"placeholder":"","show":false,"multiline":false,"value":0,"password":false,"name":"presence_penalty","type":"float","list":false},"n":{"required":false,"placeholder":"","show":false,"multiline":false,"value":1,"password":false,"name":"n","type":"int","list":false},"best_of":{"required":false,"placeholder":"","show":false,"multiline":false,"value":1,"password":false,"name":"best_of","type":"int","list":false},"model_kwargs":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"model_kwargs","type":"code","list":false},"openai_api_key":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","type":"str","list":false},"batch_size":{"required":false,"placeholder":"","show":false,"multiline":false,"value":20,"password":false,"name":"batch_size","type":"int","list":false},"request_timeout":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"request_timeout","type":"Union[float, Tuple[float, float], NoneType]","list":false},"logit_bias":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"logit_bias","type":"code","list":false},"max_retries":{"required":false,"placeholder":"","show":false,"multiline":false,"value":6,"password":false,"name":"max_retries","type":"int","list":false},"streaming":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"streaming","type":"bool","list":false},"_type":"OpenAI"},"description":"Generic OpenAI class that uses model name.","base_classes":["OpenAI","BaseLanguageModel","BaseOpenAI","BaseLLM"]},"ChatOpenAI":{"template":{"verbose":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"verbose","type":"bool","list":false},"client":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"client","type":"Any","list":false},"model_name":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"gpt-3.5-turbo","password":false,"options":["gpt-3.5-turbo","gpt-4","gpt-4-32k"],"name":"model_name","type":"str","list":true},"temperature":{"required":false,"placeholder":"","show":true,"multiline":false,"value":0.7,"password":false,"name":"temperature","type":"float","list":false},"model_kwargs":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"model_kwargs","type":"code","list":false},"openai_api_key":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","type":"str","list":false},"request_timeout":{"required":false,"placeholder":"","show":false,"multiline":false,"value":60,"password":false,"name":"request_timeout","type":"int","list":false},"max_retries":{"required":false,"placeholder":"","show":false,"multiline":false,"value":6,"password":false,"name":"max_retries","type":"int","list":false},"streaming":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"streaming","type":"bool","list":false},"n":{"required":false,"placeholder":"","show":false,"multiline":false,"value":1,"password":false,"name":"n","type":"int","list":false},"max_tokens":{"required":false,"placeholder":"","show":true,"multiline":false,"password":true,"name":"max_tokens","type":"int","list":false},"_type":"ChatOpenAI"},"description":"Wrapper around OpenAI Chat large language models.To use, you should have the ``openai`` python package installed, and theenvironment variable ``OPENAI_API_KEY`` set with your API key.Any parameters that are valid to be passed to the openai.create call can be passedin, even if not explicitly saved on this class.","base_classes":["BaseChatModel","BaseLanguageModel","ChatOpenAI"]}},"memories":{"ConversationBufferMemory":{"template":{"chat_memory":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"chat_memory","type":"BaseChatMessageHistory","list":false},"output_key":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"output_key","type":"str","list":false},"input_key":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"input_key","type":"str","list":false},"return_messages":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"return_messages","type":"bool","list":false},"human_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"Human","password":false,"name":"human_prefix","type":"str","list":false},"ai_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"AI","password":false,"name":"ai_prefix","type":"str","list":false},"memory_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"history","password":true,"name":"memory_key","type":"str","list":false},"_type":"ConversationBufferMemory"},"description":"Buffer for storing conversation memory.","base_classes":["ConversationBufferMemory","BaseChatMemory","BaseMemory"]},"ConversationKGMemory":{"template":{"chat_memory":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"chat_memory","type":"BaseChatMessageHistory","list":false},"output_key":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"output_key","type":"str","list":false},"input_key":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"input_key","type":"str","list":false},"return_messages":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"return_messages","type":"bool","list":false},"k":{"required":true,"placeholder":"","show":true,"multiline":false,"value":10,"password":false,"name":"k","display_name":"Memory Size","type":"int","list":false},"human_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"Human","password":false,"name":"human_prefix","type":"str","list":false},"ai_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"AI","password":false,"name":"ai_prefix","type":"str","list":false},"kg":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"kg","type":"NetworkxEntityGraph","list":false},"knowledge_extraction_prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"knowledge_extraction_prompt","type":"BasePromptTemplate","list":false},"entity_extraction_prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"entity_extraction_prompt","type":"BasePromptTemplate","list":false},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLanguageModel","list":false},"summary_message_cls":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"summary_message_cls","type":"Type[langchain.schema.BaseMessage]","list":false},"memory_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"history","password":true,"name":"memory_key","type":"str","list":false},"_type":"ConversationKGMemory"},"description":"Knowledge graph memory for storing conversation memory.Integrates with external knowledge graph to store and retrieveinformation about knowledge triples in the conversation.","base_classes":["BaseChatMemory","ConversationKGMemory","BaseMemory"]},"ConversationSummaryMemory":{"template":{"human_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"Human","password":false,"name":"human_prefix","type":"str","list":false},"ai_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"AI","password":false,"name":"ai_prefix","type":"str","list":false},"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLanguageModel","list":false},"prompt":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"prompt","type":"BasePromptTemplate","list":false},"summary_message_cls":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"summary_message_cls","type":"Type[langchain.schema.BaseMessage]","list":false},"chat_memory":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"chat_memory","type":"BaseChatMessageHistory","list":false},"output_key":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"output_key","type":"str","list":false},"input_key":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"input_key","type":"str","list":false},"return_messages":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"return_messages","type":"bool","list":false},"buffer":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"","password":false,"name":"buffer","type":"str","list":false},"memory_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"history","password":true,"name":"memory_key","type":"str","list":false},"_type":"ConversationSummaryMemory"},"description":"Conversation summarizer to memory.","base_classes":["SummarizerMixin","ConversationSummaryMemory","BaseChatMemory","BaseMemory"]}},"tools":{"PAL-MATH":{"template":{"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLLM","list":false},"_type":"PAL-MATH"},"description":"A language model that is really good at solving complex word math problems. Input should be a fully worded hard word math problem.","base_classes":["Tool"]},"Calculator":{"template":{"llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","type":"BaseLLM","list":false},"_type":"Calculator"},"description":"Useful for when you need to answer questions about math.","base_classes":["Tool"]},"Serper Search":{"template":{"serper_api_key":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"","password":true,"name":"serper_api_key","type":"str","list":false},"_type":"Serper Search"},"description":"A low-cost Google Search API. Useful for when you need to answer questions about current events. Input should be a search query.","base_classes":["Tool"]},"Search":{"template":{"serpapi_api_key":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"","password":true,"name":"serpapi_api_key","type":"str","list":false},"aiosession":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"","password":false,"name":"aiosession","type":"str","list":false},"_type":"Search"},"description":"A search engine. Useful for when you need to answer questions about current events. Input should be a search query.","base_classes":["Tool"]},"Tool":{"template":{"name":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"","password":false,"name":"name","type":"str","list":false},"description":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"","password":false,"name":"description","type":"str","list":false},"func":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"func","type":"function","list":false},"_type":"Tool"},"description":"","base_classes":["Tool"]},"PythonFunction":{"template":{"code":{"required":true,"placeholder":"","show":true,"multiline":true,"value":"\ndef python_function(text: str) -> str:\n    \"\"\"This is a default python function that returns the input text\"\"\"\n    return text\n","password":false,"name":"code","type":"code","list":false},"_type":"python_function"},"description":"Python function to be executed.","base_classes":["function"]},"JsonSpec":{"template":{"dict_":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"","suffixes":[".json",".yaml",".yml"],"password":false,"name":"dict_","type":"file","list":false,"fileTypes":["json","yaml","yml"],"content":null},"max_value_length":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"","password":false,"name":"max_value_length","type":"int","list":false},"_type":"JsonSpec"},"description":"","base_classes":["Tool","JsonSpec"]}},"toolkits":{"JsonToolkit":{"template":{"spec":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"spec","type":"JsonSpec","list":false},"_type":"JsonToolkit"},"description":"Toolkit for interacting with a JSON spec.","base_classes":["JsonToolkit","BaseToolkit"]},"OpenAPIToolkit":{"template":{"json_agent":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"json_agent","type":"AgentExecutor","list":false},"requests_wrapper":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"requests_wrapper","type":"TextRequestsWrapper","list":false},"_type":"OpenAPIToolkit"},"description":"Toolkit for interacting with a OpenAPI api.","base_classes":["OpenAPIToolkit","BaseToolkit"]}},"wrappers":{"TextRequestsWrapper":{"template":{"headers":{"required":false,"placeholder":"","show":true,"multiline":true,"value":"{'Authorization':\n            'Bearer <token>'}","password":false,"name":"headers","type":"code","list":false},"aiosession":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"aiosession","type":"ClientSession","list":false},"_type":"TextRequestsWrapper"},"description":"Lightweight wrapper around requests library.The main purpose of this wrapper is to always return a text output.","base_classes":["TextRequestsWrapper"]}}}